\glsresetall
% Research Objectives and Approach ---------------------------------------------------------------
\chapter{Research Objectives and Approach}
\label{chap:research_objectives_and_approach}

This chapter presents the research objectives and approach used in this thesis. We will start to discuss how we faced the problem, and what were the main difficulties that we found when handling this kind of problem as well as the ways we have taken to deal with it.

The debugging process in distributed systems and microservice based systems is not an easy task to perform, because of the way the system is designed using this kind of architecture style, as explained in the subsection \ref{subsec:microservices} - \nameref{subsec:microservices}. Reasoning about concurrent activities of system nodes and even understanding the system's communication topology can be very difficult. A standard approach to gaining insight into system activity is to analyze system logs, but this task can be very tedious and complex process. The main existing tools are the ones presented in \ref{subsec:monitoring_and_tracing_tools}, but they only do the job of gather and present the information to the user in a more gracefully way, however they rely on the user perception to do the search to find issues that exist in their platform by performing queries to the spans and trace data. So, with this problem ahead, we started looking for the needs of Sysadmins and/or \gls{devops} when they wanted to scan and analyse their system searching for issues.

To do this and narrow the problem we were facing, we decided to talk with some \gls{devops} personal and expose them the situation, with the objective to gather their main needs and ideas in mind, we putted ourselves in their perspective when talking to them to try and find what are the main difficulties when they perform their search for issues in the system in a \textit{``As a \gls{devops} i want to...''} situation. The kind of questions that were placed were like: \textit{``What are the most common issues?''}, \textit{``What are the variables involved in this kind of issues?''} and \textit{``What are the correlations between this variables and the most common issues?''}. From this discussions and conversations emerged the following eight core questions:

\begin{itemize}
    \item[\textbf{1.}] What is the neighbourhood of one service?
    \item[\textbf{2.}] Is there any problem (Which are the associated heuristics)?
    \item[\textbf{3.}] Is there any faults related to the system design/architecture?
    \item[\textbf{4.}] What is the root problem, when A, B, C services are slow?
    \item[\textbf{5.}] How are the requests coming from the client?
    \item[\textbf{6.}] How endpoints orders distributions are done?
    \item[\textbf{7.}] What is the behaviour of the instances?
    \item[\textbf{8.}] What is the length of each queue in a service?
\end{itemize}

The next step was to work on the questions presented above. We decided to split them in more concise questions, refine and filter the most relevant to define our objective, and after that, check with someone involved in the \gls{devops} field if the final questions represent some of their needs. First, to handle the information presented in this eight initial questions, we decided to create what we called a ``Project Questions Board''. This board consists on a Kanban \cite{kanban_board} style board present in the project git repository, were everyone involved in the project could access and modify it. The board was defined with four lanes: ``To refine'', ``Interesting'', ``Refined'' and ``Final Questions'', and the process were to cycle the questions through every lane, generating new ones and filtering others. After this, and to check if the final questions were really some that represented the needs of a \gls{devops}, some colleagues that work directly in the field were contacted and the questions were exposed to them. In the end, the ten questions that were produced in the final lane represented right what are some of their needs. The final questions, their corresponding description\textbf{(D)} and explanation of the expected work\textbf{(W)} that must be performed to each one are exposed bellow:

\begin{itemize}
    \item[\textbf{1.}] What is the neighbourhood of one service, based on incoming requests? \begin{itemize}
        \item[D.] The neighbourhood of one service is a very important information to know due to the simple fact that it represents the interaction between the microservices. The incoming requests can map the interactions between the microservices and with this kind of information, we can check and analyse the service dependencies.
        \item[W.] Implies generate a graph, based on the spans and traces, using the outgoing connections, from a certain node, that are correlated with the incoming connection(s).
    \end{itemize}

    \item[\textbf{2.}] What is the neighbourhood of one service, based on outgoing requests?
    \begin{itemize}
        \item[D.] Similar to the previous question, but this time, instead of incoming requests we focus on the outgoing requests of one service. 
        \item[W.] Implies generate a graph, based on the spans and traces, using the incoming connections, from a certain node, that are correlated with the outgoing connection(s).
    \end{itemize}

    \item[\textbf{3.}] How endpoints orders distributions are done, when using a specific endpoint?
    \begin{itemize}
        \item[D.] The distributions of microservices in a system allows us to understand if a certain endpoint groups with others or if it is an isolated service, which stands for its relevance to the whole system.
        \item[W.] Implies generate a graph, based on the spans and traces, then calculate the degree of a certain node that represents the endpoint, to finally check if it is an isolated, a leaf or a dominating (high or low depending on the degree of the other degrees) endpoint.
    \end{itemize}
    
    \item[\textbf{4.}] How requests are being handled by a specific endpoint?
    \begin{itemize}
        \item[D.] This question has the objective of analyse the status of the requests that arrive or depart from a specific endpoint. This status represents if the requests was well succeed or not.
        \item[W.] Implies to analyse the data from the requests that pass through a specific endpoint. Based on the annotations presented in the spans and traces, we are able to check if the requests are resulting in success or in error. 
    \end{itemize}

    \item[\textbf{5.}] Which endpoints are the most popular?
    \begin{itemize}
        \item[D.] The popularity of a certain endpoint is very important because it represents the importance of this endpoint to the system.
        \item[W.] Implies to retrieve the most popular service, based on the spans and traces, and get the services with more incoming connections sorted by the number of incoming connections.
    \end{itemize}

    \item[\textbf{6.}] Is there any problem related to the response time?
    \begin{itemize}
        \item[D.] Response time is must watch variable because, for example, strange high values may represent a problem in the system performance.
        \item[W.] Implies to get the response time of every trace (difference between end and start time of every span in the trace) and then calculate and store some measurements like the average time, the maximum time, the minimum time and variance. After having some stored values, the system must perform calculations and check if there is too much disparity between them to determine if there is a problem in the response time.
    \end{itemize}

    \item[\textbf{7.}] Is there any problem related to the morphology?
    \begin{itemize}
        \item[D.] The morphology of the system allows us to understand if some endpoints are common in the system (they usually exist), or if they only are instantiated in specific situations.
        \item[W.] Implies generate multiple graphs, based on a certain group of spans and traces that are contained in a certain time interval. Then we need to store the graphs gradually using some graph storing mechanism to perform the difference of subsequent stored graphs. This result of the difference between graphs must be stored in a time-series storing mechanism, to be accessed later and determine if there were hard changes that could lead to morphology problems in the system thought time.
    \end{itemize}
    
    \item[\textbf{8.}] Is there any problem related to the entire workflow of (one or more) requests?
    \begin{itemize}
        \item[D.] Analyse the request workflow through the system is a good practice, as it represents the interaction triggered by the request in the system and its resulting behaviour. This can lead to find out if the system has cycles and if they are normal or represent a problem to solve.  
        \item[W.] Implies to generate the graph of the system, identify the path of some request(s) in the system and then perform the calculation to verify and identify if there were cycles presented in the graph involved in the path of the request(s). The results of this calculations must be stored in a time-series storing mechanism, to be accessed later and determine if this cycles are normal, or if they represent a problem related to the request(s) work-flow, based on the kind of request.
    \end{itemize}

    \item[\textbf{9.}] Is there any problem related to the occupation/load of a specific endpoint?
    \begin{itemize}
        \item[D.] The occupation/load of a specific endpoint in this case is represented by the number of requests in queue of a specific endpoint. This value is very important because it represents if the endpoint is in overflow or not.
        \item[W.] Implies to get the number of requests in queue of a specific endpoint and then calculate and store some measurements like the average, maximum, minimum and variance of the number of requests in queue. After having some stored values, the system must perform calculations and check if there is too much disparity between them to determine if there is a problem in the occupation/load.
    \end{itemize}

    \item[\textbf{10.}] Is there any problem, related to the number/profile of the client requests?
    \begin{itemize}
        \item[D.] The number of client requests and their corresponding profile represents the behaviour of clients when using the system. This can be used to identify problems of bad system usage from the clients, like for example a DDoS (Denial Of Service).
        \item[W.] Implies calculate the number of accesses to the system, based on the spans and traces annotated with client requests of a certain time interval, and store the calculations for every node. After having some stored values, the system must determine the level regions of access based in the available data (profile of requests, ex.: high, moderate and low), and check if there were to much requests outside of the defined level regions.
    \end{itemize}
\end{itemize}

 These final questions, with a slight reformulation, could be exported to high level of abstraction functional requirements of the monitoring tool that we want to develop. After having this questions, we decided to study the current state of art to check how things are done nowadays regarding this subject and we found that some tools perform the process of convert spans and traces to a graph, that represents the system at that current time interval, however they do not perform any kind of analysis and study over the span tree and the graph after that\cite{spans_analysis}.
 
 Considering this, what we decided to do was to develop a simple prototype tool to test some state of the art tools. What we were able to achieve was to do the reconstruction of the graph, using our own data (this data was provided by Prof. Jorge Cardoso, representing an approximate two hour collection of spans and traces, about 400.000 spans, generated by one of their clusters). At this point, and since we have already held the hands-on of some tools at the moment, we were ready to start and think about the solution we need to build. Therefore, we decided to specify the solution, and considered to build a monitoring tool named by ourselves, \textit{Graphy}.
 
 In a very briefly explanation, we want that \textit{Graphy} be able to calculate relevant metrics from the span trees and the generated graphs, and to work with this kind of metrics to perform the system analysis and answer the questions exposed above. To perform some of this work, it will be resourcing to machine learning algorithms that we will need to study in parallel with the implementation, as we cannot predict what we might encounter when retrieving the metrics at the time. The machine learning algorithms are to process the metrics and perform some deductions regarding the system behaviour over the time.
%-------------------------------------------------------------------------------------------------


%-------------------------------------------------------------------------------------------------
\checkoddpage
\ifthenelse{\boolean{oddpage}}
{ % Odd page
\newpage
\blankpage}
{ % Even page
}
%-------------------------------------------------------------------------------------------------